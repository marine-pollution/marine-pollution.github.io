<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="MADOS - Marine Pollution"/>
  <meta property="og:description" content="MADOS - Marine Pollution"/>
  <meta property="og:url" content="marine-pollution.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/MADOS_LOGO.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MADOS - Marine Pollution">
  <meta name="twitter:description" content="MADOS - Marine Pollution">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/MADOS_LOGO.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Sentinel-2, Deep Learning, Benchmark, Data Augmentation, Marine Pollution, Marine Debris, Oil Spill">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MADOS - Marine Pollution</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
			  <!-- Image next to the title -->
			  <div class="title-container is-flex is-align-items-center is-justify-content-center">
				<img src="static/images/MADOS_LOGO.png" alt="Title Icon" class="title-image">
				<h1 class="title is-1 publication-title">Detecting Marine Pollutants and Sea Surface Features with Deep Learning in Sentinel-2 Imagery</h1>
			  </div>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=JOGcM0kAAAAJ" target="_blank" style="color: black;">Katerina Kikaki</a><small><sup>1,2</sup></small>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=B_dKcz4AAAAJ" target="_blank" style="color: black;">Ioannis Kakogeorgiou</a><small><sup>1</sup></small>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=Ez_xk3sAAAAJ" target="_blank" style="color: black;">Ibrahim Hoteit</a><small><sup>3</sup></small>,
                  </span>
				  <span class="author-block">
                    <a href="https://scholar.google.gr/citations?user=U6t7QpsAAAAJ" target="_blank" style="color: black;">Konstantinos Karantzalos</a><small><sup>1</sup></small>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><small><sup>1</sup></small>National Technical University of Athens, <small><sup>2</sup></small>Hellenic Centre for Marine Research,<br><small><sup>3</sup></small>King Abdullah University of Science and Technology<br>ISPRS Journal of Photogrammetry and Remote Sensing - 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- ISPRS PDF link -->
                      <span class="link-block">
                        <a href="https://www.sciencedirect.com/science/article/pii/S0924271624000625" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/gkakogeorgiou/mados" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Dataset Link -->
                <span class="link-block">
                  <a href="https://doi.org/10.5281/zenodo.10664073" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
			  
                <!-- EDA Link -->
                <span class="link-block">
                  <a href="home.html" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-chart-bar"></i>
                  </span>
                  <span>Exploratory analysis</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/mados_teaser_debris_oil.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        We introduce a new open-access dataset named MADOS, which includes 15 classes,<br>featuring oil spills and marine debris, based on Sentinel-2 multispectral satellite data.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite the significant negative impact of marine pollution on the ecosystem and humans, its automated detection and tracking from the broadly available satellite data is still a major challenge. In particular, most research and development efforts focus on one specific pollutant implementing, in most cases, binary classification tasks, e.g., detect Plastics or no Plastics, or target a limited number of classes, such as Oil Spill, Look-alikes and Water. Moreover, most developed algorithms tend to operate successfully only locally, failing to scale and generalize adequately towards operational deployments. Our aim is to address these challenges by introducing a holistic approach towards marine pollutant detection using remote sensing. We argue that constructing such operational solutions requires detectors trained and tested against different types of pollutants, various sea surface features and water-related thematic classes. We offer such a Marine Debris and Oil Spill (MADOS) dataset, composed of high-resolution multispectral Sentinel-2 (S2) data, consisting of 174 scenes captured between 2015-2022, with approximately 1.5M annotated pixels, which are globally distributed and collected under various weather conditions. Moreover, we propose a novel Deep Learning (DL) framework named MariNeXt, based on recent state-of-the-art architectural advancements for semantic segmentation, which outperforms all baselines by at least 12% in F1 and mIoU metrics. The extensive quantitative and qualitative validation justifies our choices and demonstrates the high potential of the proposed approach. We further discuss the underlying discrimination challenges among the competing thematic classes. Our dataset, code and trained models are openly available to stimulate further research.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">MADOS Overview</h2>
      <p> Overview of MADOS provided patches. Marine pollutants and Sea surface features were annotated under various weather and sea state conditions. </p>

      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/mados_overview_lower_1.png" alt="MY ALT TEXT"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/mados_overview_lower_2.png" alt="MY ALT TEXT"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/mados_overview_lower_3.png" alt="MY ALT TEXT"/>
     </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">MADOS thematic classes and annotations</h2>
      <p> MADOS contains annotated Sentinel-2 data based on 174 scenes and 47 tiles captured between 2015-2022.</p>

      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/annotated_tiles.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The globally distributed Sentinel-2 tiles from which MADOS data were sampled.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/table_3.png" alt="MY ALT TEXT" width="900">
        <h2 class="subtitle has-text-centered">
          MADOS Thematic Classes. Per-class description, acronym, number of image patches and corresponding annotated pixels.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">MariNeXt</h2>
      <p> We propose a novel deep learning framework named MariNeXt, which outperforms all baselines by at least 12% in F1. </p>

      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/figure_2_lower.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Simplified overview of MariNeXt, which consists of two main parts: a) During the training process, the input batch of images is augmented using the VSCP module combing the samples, which are then passed as new input. Then MariNeXt exploits the SegNeXt's S1 (1st-Stage Higher Resolution Features) to produce fine-grained predictions. b) During testing, the Test-Time Augmentation (TTA) strategy is employed to produce several augmented views of the input image and aggregate the predictions by major voting, producing refined predictions.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/figure_4_lower.png" alt="MY ALT TEXT" width="1100">
        <h2 class="subtitle has-text-centered">
          Prediction maps extracted by the applied baselines and MariNeXt. The RGB images show: a) Dense & sparse Sargassum, Marine Water and haze/thin clouds, b) Oil Spill and Marine Water, c) Marine Debris and Marine Water, and d) Jellyfish and rough sea state. The RGB images were stretched for illustration purposes.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/table_4.png" alt="MY ALT TEXT" width="900">
        <h2 class="subtitle has-text-centered">
          Evaluation of MariNeXt against baselines on MADOS test set using F1, mean Intersection of Union (mIoU) and Overall Accuracy (OA) metrics, averaged over five trials.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{kikaki2024mados,
title = {Detecting Marine Pollutants and Sea Surface Features with Deep Learning in Sentinel-2 Imagery},
author = {Katerina Kikaki and Ioannis Kakogeorgiou and Ibrahim Hoteit and Konstantinos Karantzalos},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
year = {2024}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
